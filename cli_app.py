import argparse
import json
import logging
import os
from datetime import datetime

from tqdm import tqdm

from cli.graph.compile_graph import graph
from utils.file_utils import extract_text_from_file


def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(
        description="AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫—É—Ä–∞—Ç–æ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ –ø—Ä–∞–∫—Ç–∏–∫—É–º–∞ (–∫–æ–Ω—Å–æ–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)"
    )

    parser.add_argument(
        "--project_dir",
        "-p",
        type=str,
        default="project",
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø—Ä–æ–µ–∫—Ç–æ–º",
    )
    parser.add_argument(
        "--reports_dir",
        "-reports",
        type=str,
        default="input/reports",
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ c –æ—Ç—á–µ—Ç–∞–º–∏",
    )
    parser.add_argument(
        "--passports_dir",
        "-passports",
        type=str,
        default="input/passports",
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ c –ø–∞—Å–ø–æ—Ä—Ç–∞–º–∏",
    )
    parser.add_argument(
        "--criteria_file_path",
        "-c",
        type=str,
        default="–ö—Ä–∏—Ç–µ—Ä–∏–∏.txt",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ –æ—Ü–µ–Ω–∫–∏ (TXT)",
    )
    parser.add_argument(
        "--output_dir",
        "-o",
        type=str,
        default="output",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )
    parser.add_argument(
        "--model",
        "-m",
        type=str,
        default="DeepSeek Chat",
        help="–ù–∞–∑–≤–∞–Ω–∏–µ LLM –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
    )
    parser.add_argument(
        "--skip-feedback",
        "-s",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞",
    )

    return parser.parse_args()


def setup_environment(args, output_dir):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(output_dir, exist_ok=True)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å LLM –∏ –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø—Ä–æ–µ–∫—Ç–æ–º
    os.environ["LLM_MODEL"] = args.model
    os.environ["PROJECT_DIR"] = args.project_dir


def load_criteria(criteria_file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤"""
    if not os.path.isfile(criteria_file_path):
        logging.error(f"–§–∞–π–ª —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {criteria_file_path}")
        raise FileNotFoundError(f"–§–∞–π–ª —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {criteria_file_path}")

    criteria = extract_text_from_file(criteria_file_path)
    return criteria


def read_file_content(file_path):
    """–ß—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞"""
    if not file_path:
        raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")

    if not os.path.isfile(file_path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

    return extract_text_from_file(file_path)


def save_results(file_name, results, output_dir, skip_feedback):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∏"""

    base_result_path = os.path.join(output_dir, os.path.splitext(file_name)[0])
    result_path = base_result_path
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Å—É—Ñ—Ñ–∏–∫—Å–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    counter = 1
    while os.path.exists(f"{result_path}_check_results.md"):
        result_path = f"{base_result_path}_{counter}"
        counter += 1

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
    with open(f"{result_path}_check_results.md", "w", encoding="utf-8") as f:
        f.write(results.get("check_results", ""))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    with open(f"{result_path}_criteria.md", "w", encoding="utf-8") as f:
        f.write(results.get("criteria", ""))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
    if not skip_feedback:
        with open(f"{result_path}_feedback.md", "w", encoding="utf-8") as f:
            f.write(results.get("feedback", ""))


def check_input_format(reports_dir, passports_dir):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""

    supported_formats = (".txt", ".pdf", ".docx")

    dirs = [reports_dir, passports_dir]
    for dir in dirs:
        for file_name in os.listdir(dir):
            if not file_name.endswith(supported_formats):
                logging.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {file_name}, –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {supported_formats}.")
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {file_name}, –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {supported_formats}.")


def main():

    args = parse_arguments()

    project_dir = args.project_dir
    reports_dir = os.path.join(project_dir, args.reports_dir)
    passports_dir = os.path.join(project_dir, args.passports_dir)
    output_dir = os.path.join(project_dir, args.output_dir)
    criteria_file_path = os.path.join(project_dir, args.criteria_file_path)
    status_file_path = os.path.join(project_dir, "docs_status.json")
    skip_feedback = args.skip_feedback

    logging.basicConfig(
        level=logging.INFO,
        handlers=[
            logging.FileHandler(
                os.path.join(project_dir, "ai_assistant_pp.log"),
                mode="a",
                encoding="utf-8",
            ),
            logging.StreamHandler(),
        ],
        format="%(asctime)s - %(levelname)s - %(message)s",
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    check_input_format(reports_dir, passports_dir)

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
    setup_environment(args, output_dir)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏
    criteria = load_criteria(criteria_file_path)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
    try:
        with open(status_file_path, "r", encoding="utf-8") as f:
            docs_status = json.load(f)
    except FileNotFoundError:
        docs_status = {}

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Å–ø–æ—Ä—Ç–æ–≤
    has_passports = len(os.listdir(passports_dir)) > 0
    if not has_passports:
        logging.warning(
            "–ü–∞–ø–∫–∞ —Å –ø–∞—Å–ø–æ—Ä—Ç–∞–º–∏ –ø—É—Å—Ç–∞. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ —Å —É—á–µ—Ç–æ–º –ø–∞—Å–ø–æ—Ä—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –Ω–µ –±—É–¥–µ—Ç."
        )

    processed_passports = []
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç—ã
    for file_name in tqdm(os.listdir(reports_dir), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç—á–µ—Ç–æ–≤"):

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
        if file_name in docs_status:
            if docs_status[file_name]["status"] == "success":
                continue

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
        docs_status[file_name] = dict.fromkeys(
            ["status", "error_message", "processed_at"]
        )

        try:
            report = read_file_content(os.path.join(reports_dir, file_name))
            report_file_name = os.path.splitext(file_name)[0]

            passport = ""

            # –ò—â–µ–º –ø–∞—Å–ø–æ—Ä—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if has_passports:
                for passport_file in os.listdir(passports_dir):
                    if (
                        report_file_name.lower() in passport_file.lower()
                        and passport_file not in processed_passports
                    ):
                        passport = read_file_content(
                            os.path.join(passports_dir, passport_file)
                        )
                        processed_passports.append(passport_file)
                        break

            results = graph.invoke(
                {
                    "report": report,
                    "criteria": criteria,
                    "passport": passport,
                    "skip_feedback": skip_feedback,
                }
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
            save_results(file_name, results, output_dir, skip_feedback)
            docs_status[file_name]["status"] = "success"
            logging.info(f"‚úÖ –§–∞–π–ª {file_name} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        except Exception as e:
            docs_status[file_name]["status"] = "error"
            docs_status[file_name]["error_message"] = str(e)
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_name}: {str(e)}")
        finally:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è, –≤ –∫–æ—Ç–æ—Ä–æ–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª
            docs_status[file_name]["processed_at"] = datetime.now().strftime(
                "%Y-%m-%d %H:%M:%S"
            )

    logging.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    logging.info(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")

    with open(status_file_path, "w", encoding="utf-8") as f:
        json.dump(docs_status, f, ensure_ascii=False, indent=4)


if __name__ == "__main__":
    main()
